{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:00:39.122602Z",
     "start_time": "2025-06-03T23:00:39.116348Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/supernova/miniconda3/envs/360/bin/python3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:00:39.127918Z",
     "start_time": "2025-06-03T23:00:39.125888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "# make sure INFO (or DEBUG) logs go to your console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"detectron2.engine.defaults\").setLevel(logging.INFO)"
   ],
   "id": "1f5d77084e29cd2e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "33898023b16354e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:00:40.911796Z",
     "start_time": "2025-06-03T23:00:39.151570Z"
    }
   },
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "\n",
    "# 1. Define your “real” COCO IDs and your class names:\n",
    "COCO_IDS = [0, 1, 2, 3, 5, 7, 9]\n",
    "CLASS_NAMES = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\", \"traffic light\"]\n",
    "\n",
    "\n",
    "# 2. Register your dataset, telling Detectron2 how to map\n",
    "#    your JSON’s category_id (which you’ve numbered 1–7) back\n",
    "#    to the real COCO IDs above.\n",
    "def register_my_dataset(name, json_file, image_root):\n",
    "    # build a map:  json_id (1–7)  →  contiguous id (0–6)\n",
    "\n",
    "    dataset_id_to_contiguous = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6}\n",
    "    MetadataCatalog.get(\"myval7\").set(\n",
    "        json_file=json_file,\n",
    "        image_root=image_root,\n",
    "        evaluator_type=\"coco\",\n",
    "        thing_classes=CLASS_NAMES,\n",
    "        thing_dataset_id_to_contiguous_id=dataset_id_to_contiguous,\n",
    "    )\n",
    "    DatasetCatalog.register(\n",
    "        name,\n",
    "        lambda: load_coco_json(json_file, image_root, name),\n",
    "    )\n",
    "\n",
    "register_my_dataset(\n",
    "    \"my_val\",\n",
    "    \"/Users/supernova/360_object_tracking/video1/COCO/annotations/instances_default.json\",\n",
    "    \"/Users/supernova/360_object_tracking/video1/COCO/val\"\n",
    ")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:00:40.923401Z",
     "start_time": "2025-06-03T23:00:40.921296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tell Detectron2 how many classes and what their names are:\n",
    "MetadataCatalog.get(\"my_val\").thing_classes = ['person', 'bicycle', 'car', 'motorbike', 'bus', 'truck', 'traffic light']\n",
    "# Now the metadata has been populated:\n",
    "print(MetadataCatalog.get(\"my_val\").thing_classes)\n",
    "# → ['person', 'bicycle', 'car', 'motorbike', 'bus', 'truck', 'traffic light']"
   ],
   "id": "5ada6efe496114cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'bus', 'truck', 'traffic light']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:00:41.784969Z",
     "start_time": "2025-06-03T23:00:40.931180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "import torch\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "input_size=1280\n",
    "score_threshold=0.4\n",
    "# nms_threshold=0.45\n",
    "\n",
    "# choose a model from detectron2's model zoo\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    ")\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TEST = input_size  # set the size of the input images\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = (\n",
    "    score_threshold  # set the threshold of the confidence score\n",
    ")\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\n",
    "# cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = nms_threshold  # set the NMS threshold\n",
    "\n",
    "# set the device to use (GPU or CPU)\n",
    "if torch.cuda.is_available():\n",
    "    cfg.MODEL.DEVICE = \"cuda\"\n",
    "else:\n",
    "    cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "    # only work on apple m1 mac\n",
    "    # cfg.MODEL.DEVICE = 'mps'\n",
    "\n",
    "# create a predictor instance with the config above\n",
    "predictor_faster_RCNN = DefaultPredictor(cfg)\n",
    "\n",
    "# Build a DataLoader for the \"my_val\" split\n",
    "val_loader = build_detection_test_loader(cfg, \"my_val\")"
   ],
   "id": "f37e563807de7c15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n",
      "INFO:iopath.common.file_io:URL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl cached in /Users/supernova/.torch/iopath_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "INFO:fvcore.common.checkpoint:Reading a file from 'Detectron2 Model Zoo'\n",
      "INFO:detectron2.data.datasets.coco:Loaded 420 images in COCO format from /Users/supernova/360_object_tracking/video1/COCO/annotations/instances_default.json\n",
      "INFO:detectron2.data.dataset_mapper:[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1280, 1280), max_size=1333, sample_style='choice')]\n",
      "INFO:detectron2.data.common:Serializing 420 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 0.61 MiB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-03T23:00:41.788449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Grab one batch\n",
    "batch = next(iter(val_loader))  # yields a list of dicts, one per image\n",
    "\n",
    "# 2) Inspect the keys of the first example\n",
    "example = batch[0]\n",
    "print(example)\n",
    "\n",
    "print(example.keys())\n"
   ],
   "id": "5904d1f8eb627856",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "# 1) load the raw dicts\n",
    "dataset_dicts = DatasetCatalog.get(\"my_val\")\n",
    "\n",
    "# 2) sample 3 at random\n",
    "samples = random.sample(dataset_dicts, 3)\n",
    "\n",
    "# 3) visualize each\n",
    "metadata = MetadataCatalog.get(\"my_val\")\n",
    "for d in samples:\n",
    "    img = cv2.imread(d[\"file_name\"])                 # BGR uint8\n",
    "    vis = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)\n",
    "    out = vis.draw_dataset_dict(d)                   # draws d[\"annotations\"]\n",
    "    out_rgb = out.get_image()                        # RGB H×W×3\n",
    "\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(out_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "id": "734cf984a02f870",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from detectron2.evaluation import COCOEvaluator\n",
    "# 4) subclass COCOEvaluator to filter & remap on the fly\n",
    "\n",
    "# class FilterAndRemapCOCOEvaluator(COCOEvaluator):\n",
    "#     def process(self, inputs, outputs):\n",
    "#         # inputs: list of dicts, outputs: list of dicts with \"instances\"\n",
    "#         new_inputs, new_outputs = [], []\n",
    "#         for inp, out in zip(inputs, outputs):\n",
    "#             inst = out[\"instances\"].to(\"cpu\")\n",
    "#             # keep only predictions whose class is in our COCO_IDS\n",
    "#             keep_mask = [(c in COCO_IDS) for c in inst.pred_classes.tolist()]\n",
    "#             if not any(keep_mask):\n",
    "#                 # no valid preds for this image → skip\n",
    "#                 continue\n",
    "#             inst = inst[keep_mask]\n",
    "#             # remap class indices: e.g. if pred_classes=[0,5,9], new → [0,4,6]\n",
    "#             remapped = [COCO2CONT[int(c)] for c in inst.pred_classes.tolist()]\n",
    "#             inst.pred_classes = torch.tensor(remapped)\n",
    "#             out[\"instances\"] = inst\n",
    "#             new_inputs.append(inp)\n",
    "#             new_outputs.append(out)\n",
    "#\n",
    "#         # now call the parent with filtered/remapped lists\n",
    "#         super().process(new_inputs, new_outputs)\n",
    "\n",
    "# You can specify which tasks to compute; by default it infers from dataset (bbox, segm, keypoints…)\n",
    "evaluator = COCOEvaluator(\n",
    "    dataset_name=\"my_val\",   # the name you registered\n",
    "    tasks=(\"bbox\",),         # e.g., \"bbox\", \"segm\", or (\"bbox\", \"segm\")\n",
    "    distributed=False,       # set True if using multi-GPU\n",
    "    output_dir=\"./output\"    # where to dump JSON results & summaries\n",
    ")"
   ],
   "id": "d6cf7573644bb196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from detectron2.evaluation import inference_on_dataset\n",
    "# AssertionError: A prediction has class=11, but the dataset only has 7 classes and predicted class id should be in [0, 6].\n",
    "# We need to filter out unnecessary classes\n",
    "metrics = inference_on_dataset(\n",
    "    predictor_faster_RCNN.model,  # or Trainer.model\n",
    "    val_loader,\n",
    "    evaluator,\n",
    "    COCO_IDS,\n",
    "    False\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "7d7c8beb647342d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:38:27.067946Z",
     "start_time": "2025-05-23T21:38:26.586781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "coco_gt = COCO(\"/Users/supernova/360_object_tracking/video1/COCO/annotations/instances_default.json\")\n",
    "coco_dt = coco_gt.loadRes(\"predictions.json\")\n",
    "\n",
    "evaluator = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "evaluator.evaluate()\n",
    "evaluator.accumulate()\n",
    "evaluator.summarize()"
   ],
   "id": "6fe3ed19952a07bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "360kernel",
   "language": "python",
   "name": "360kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
